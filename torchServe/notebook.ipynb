{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "058de3b3-0a4f-42e6-b512-7756ff894e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b86697fc-9edf-4070-85f0-45f3ca3542aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_train_time(start, end):\n",
    "    print(f\"\\ntrain time: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6709f273-0640-4c3a-885c-6c018e31a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"drug_consumption.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9003efa4-5a12-49c0-96d3-6ff473ba935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee8ee2de-b1a5-4222-b12b-9c889bab9084",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65b0c592-a967-4bad-b331-ebe6bb4f1614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Gender', 'Education', 'Country', 'Ethnicity', 'Nscore',\n",
       "       'Escore', 'Oscore', 'Ascore', 'Cscore', 'Impulsive', 'SS', 'Alcohol',\n",
       "       'Amphet', 'Amyl', 'Benzos', 'Caff', 'Cannabis', 'Choc', 'Coke', 'Crack',\n",
       "       'Ecstasy', 'Heroin', 'Ketamine', 'Legalh', 'LSD', 'Meth', 'Mushrooms',\n",
       "       'Nicotine', 'Semer', 'VSA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f937e960-9732-42f6-9a7d-014a2b529daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.select_dtypes(include=['number']).columns\n",
    "labels = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "097758b4-db5b-4efd-b846-72099b76cb26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Gender', 'Education', 'Country', 'Ethnicity']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#{i:len(df[i].value_counts()) for i in num_cols}\n",
    "cat_cols = [i for i in features if len(df[i].value_counts()) < 10]\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5824ab-454f-4247-a2cd-f8ca4fa2f05a",
   "metadata": {},
   "source": [
    "### Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb3759b4-1af0-437b-8603-1945a6b98d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(-0.95197): '18 - 24',\n",
       " np.float64(-0.07854): '25 - 34',\n",
       " np.float64(0.49788): '35 - 44',\n",
       " np.float64(1.09449): '45 - 54',\n",
       " np.float64(1.82213): '55 - 64',\n",
       " np.float64(2.59171): '65+'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 24\n",
    "temp = [[18 if i == 0 else start + 10*(i-1) + 1, start + 10*i] for i in range(5)]\n",
    "age_groups = [f\"{i[0]} - {i[1]}\" for i in temp]\n",
    "age_groups.append(\"65+\")\n",
    "Age_map = {j:age_groups[i] for i, j in enumerate(sorted(df[cat_cols[0]].unique()))}\n",
    "Age_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df723ea-685e-4892-bb86-7f0d2b265f51",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda052b8-2da2-4242-a627-577a83c685d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(0.48246): 'Female', np.float64(-0.48246): 'Male'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gender_map = dict(zip(df[cat_cols[1]].unique(), [\"Female\", \"Male\"]))\n",
    "Gender_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71530bf-80d0-4362-a414-0ff853a63514",
   "metadata": {},
   "source": [
    "### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "906fd221-cba8-4051-892f-09fb10b082ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{np.float64(-2.43591): 'Left School Before 16 years',\n",
       " np.float64(-1.7379): 'Left School at 16 years',\n",
       " np.float64(-1.43719): 'Left School at 17 years',\n",
       " np.float64(-1.22751): 'Left School at 18 years',\n",
       " np.float64(-0.61113): 'Some College,No Certificate Or Degree',\n",
       " np.float64(-0.05921): 'Professional Certificate/ Diploma',\n",
       " np.float64(0.45468): 'University Degree',\n",
       " np.float64(1.16365): 'Masters Degree',\n",
       " np.float64(1.98437): 'Doctorate Degree'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "education_groups = [\"Left School Before 16 years\",\n",
    "\"Left School at 16 years\",\n",
    "\"Left School at 17 years\",\n",
    "\"Left School at 18 years\",\n",
    "\"Some College,No Certificate Or Degree\",\n",
    "\"Professional Certificate/ Diploma\",\n",
    "\"University Degree\",\n",
    "\"Masters Degree\",\n",
    "\"Doctorate Degree\"]\n",
    "Education_map = dict(zip(sorted(df[cat_cols[2]].unique()), education_groups))\n",
    "Education_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fb5650-5c4a-4c62-a43a-02053c289aa1",
   "metadata": {},
   "source": [
    "### Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49b38f52-024f-4735-a360-24dbbb1a0f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-0.09765: 'Australia',\n",
       " 0.24923: 'Canada',\n",
       " -0.46841: 'New Zealan',\n",
       " -0.28519: 'Other',\n",
       " 0.21128: 'Republic of Ireland',\n",
       " 0.96082: 'UK',\n",
       " -0.57009: 'USA'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Country_map = {-0.09765 : \"Australia\",\n",
    "0.24923 : \"Canada\",\n",
    "-0.46841 : \"New Zealan\",\n",
    "-0.28519 : \"Other\",\n",
    "0.21128 : \"Republic of Ireland\",\n",
    "0.96082 : \"UK\",\n",
    "-0.57009 : \"USA\"}\n",
    "Country_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c324c6-6014-437b-81aa-1130e06f3174",
   "metadata": {},
   "source": [
    "### Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d284f627-c9c5-41fb-a921-9736afd9ecc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-0.50212: 'Asian',\n",
       " -1.10702: 'Black',\n",
       " 1.90725: 'Mixed-Black/Asian',\n",
       " 0.126: 'Mixed-White/Asian',\n",
       " -0.22166: 'Mixed-White/Black',\n",
       " 0.1144: 'Other',\n",
       " -0.31685: 'White'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ethnicity_map  = {-0.50212 : \"Asian\",\n",
    "-1.10702 : \"Black\",\n",
    "1.90725 : \"Mixed-Black/Asian\",\n",
    "0.12600 : \"Mixed-White/Asian\",\n",
    "-0.22166 : \"Mixed-White/Black\",\n",
    "0.11440 : \"Other\",\n",
    "-0.31685 : \"White\"}\n",
    "Ethnicity_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c85462-c4ab-4a8a-8371-f66118e81261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CL0': 'Never Used',\n",
       " 'CL1': 'Used over a Decade Ago',\n",
       " 'CL2': 'Used in Last Decade',\n",
       " 'CL3': 'Used in Last Year',\n",
       " 'CL4': 'Used in Last Month',\n",
       " 'CL5': 'Used in Last Week',\n",
       " 'CL6': 'Used in Last Day'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label_map = {\"CL0\" : \"Never Used\",\n",
    "\"CL1\" : \"Used over a Decade Ago\",\n",
    "\"CL2\" : \"Used in Last Decade\",\n",
    "\"CL3\" : \"Used in Last Year\",\n",
    "\"CL4\" : \"Used in Last Month\",\n",
    "\"CL5\" : \"Used in Last Week\",\n",
    "\"CL6\" : \"Used in Last Day\"}\n",
    "Label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a99fd59c-2882-46e0-a5e1-6e7fdfbb1d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = [Age_map, Gender_map, Education_map, Country_map, Ethnicity_map]\n",
    "\n",
    "for i, j in enumerate(maps):\n",
    "    df[cat_cols[i]] = df[cat_cols[i]].map(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f857359-8be7-4899-a81c-50f1a3b4fad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop([\"Semer\", \"Ethnicity\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1283e67d-c41e-4f5c-8e68-5631045734fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['18 - 24', '25 - 34', '35 - 44', '45 - 54', '55 - 64', '65+'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5cff6ca-6d7b-40d7-b77a-172801dd128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"] = df[\"Age\"].replace({'65+' : '55 - 64'})\n",
    "df[\"Age\"] = df[\"Age\"].replace({'55 - 64' : '55+'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96c80408-5d3f-4e3d-83db-9af24220e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df['Country']=='Australia')|(df['Country']=='Canada')|(df['Country']=='New Zealand')|(df['Country']=='Other')|(df['Country']=='Republic of Ireland'),'Country']='Other_countries'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a9a0285-2c67-43e9-b232-d76005d3582f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stimulants = [\"Choc\",\"Caff\",\"Amphet\", \"Coke\", \"Crack\", \"Meth\", \"Nicotine\"]\n",
    "depressants = [\"Alcohol\", \"Benzos\", \"Heroin\", \"Legalh\", \"Amyl\", \"VSA\"]\n",
    "hallucinogens = [\"LSD\", \"Mushrooms\", \"Ketamine\", \"Cannabis\", \"Ecstasy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50d51124-0209-4f9c-b104-aa82ceaf526b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education</th>\n",
       "      <th>Country</th>\n",
       "      <th>Nscore</th>\n",
       "      <th>Escore</th>\n",
       "      <th>Oscore</th>\n",
       "      <th>Ascore</th>\n",
       "      <th>Cscore</th>\n",
       "      <th>Impulsive</th>\n",
       "      <th>...</th>\n",
       "      <th>Crack</th>\n",
       "      <th>Ecstasy</th>\n",
       "      <th>Heroin</th>\n",
       "      <th>Ketamine</th>\n",
       "      <th>Legalh</th>\n",
       "      <th>LSD</th>\n",
       "      <th>Meth</th>\n",
       "      <th>Mushrooms</th>\n",
       "      <th>Nicotine</th>\n",
       "      <th>VSA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35 - 44</td>\n",
       "      <td>Female</td>\n",
       "      <td>Professional Certificate/ Diploma</td>\n",
       "      <td>UK</td>\n",
       "      <td>0.31287</td>\n",
       "      <td>-0.57545</td>\n",
       "      <td>-0.58331</td>\n",
       "      <td>-0.91699</td>\n",
       "      <td>-0.00665</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25 - 34</td>\n",
       "      <td>Male</td>\n",
       "      <td>Doctorate Degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>-0.67825</td>\n",
       "      <td>1.93886</td>\n",
       "      <td>1.43533</td>\n",
       "      <td>0.76096</td>\n",
       "      <td>-0.14277</td>\n",
       "      <td>-0.71126</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL3</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL4</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35 - 44</td>\n",
       "      <td>Male</td>\n",
       "      <td>Professional Certificate/ Diploma</td>\n",
       "      <td>UK</td>\n",
       "      <td>-0.46725</td>\n",
       "      <td>0.80523</td>\n",
       "      <td>-0.84732</td>\n",
       "      <td>-1.62090</td>\n",
       "      <td>-1.01450</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18 - 24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Masters Degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>-0.14882</td>\n",
       "      <td>-0.80615</td>\n",
       "      <td>-0.01928</td>\n",
       "      <td>0.59042</td>\n",
       "      <td>0.58489</td>\n",
       "      <td>-1.37983</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35 - 44</td>\n",
       "      <td>Female</td>\n",
       "      <td>Doctorate Degree</td>\n",
       "      <td>UK</td>\n",
       "      <td>0.73545</td>\n",
       "      <td>-1.63340</td>\n",
       "      <td>-0.45174</td>\n",
       "      <td>-0.30172</td>\n",
       "      <td>1.30612</td>\n",
       "      <td>-0.21712</td>\n",
       "      <td>...</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL1</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL0</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL2</td>\n",
       "      <td>CL0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Gender                          Education Country   Nscore  \\\n",
       "0  35 - 44  Female  Professional Certificate/ Diploma      UK  0.31287   \n",
       "1  25 - 34    Male                   Doctorate Degree      UK -0.67825   \n",
       "2  35 - 44    Male  Professional Certificate/ Diploma      UK -0.46725   \n",
       "3  18 - 24  Female                     Masters Degree      UK -0.14882   \n",
       "4  35 - 44  Female                   Doctorate Degree      UK  0.73545   \n",
       "\n",
       "    Escore   Oscore   Ascore   Cscore  Impulsive  ...  Crack Ecstasy Heroin  \\\n",
       "0 -0.57545 -0.58331 -0.91699 -0.00665   -0.21712  ...    CL0     CL0    CL0   \n",
       "1  1.93886  1.43533  0.76096 -0.14277   -0.71126  ...    CL0     CL4    CL0   \n",
       "2  0.80523 -0.84732 -1.62090 -1.01450   -1.37983  ...    CL0     CL0    CL0   \n",
       "3 -0.80615 -0.01928  0.59042  0.58489   -1.37983  ...    CL0     CL0    CL0   \n",
       "4 -1.63340 -0.45174 -0.30172  1.30612   -0.21712  ...    CL0     CL1    CL0   \n",
       "\n",
       "  Ketamine Legalh  LSD Meth Mushrooms Nicotine  VSA  \n",
       "0      CL0    CL0  CL0  CL0       CL0      CL2  CL0  \n",
       "1      CL2    CL0  CL2  CL3       CL0      CL4  CL0  \n",
       "2      CL0    CL0  CL0  CL0       CL1      CL0  CL0  \n",
       "3      CL2    CL0  CL0  CL0       CL0      CL2  CL0  \n",
       "4      CL0    CL1  CL0  CL0       CL2      CL2  CL0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "960c5418-4961-438d-afeb-8955aa81d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## df.to_csv(\"drug.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc0b1720-4111-4dc6-a976-658bc0349171",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_cols = df.iloc[:, 4:(4+7)].columns\n",
    "demo_cols = df.iloc[:, :4].columns\n",
    "drug_cols = df.iloc[:, 11:].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "933e125e-8375-46a7-ad89-4c13a7511a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CL0', 'CL1', 'CL2', 'CL3', 'CL4', 'CL5', 'CL6'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df.Alcohol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed254d95-33e0-4ecf-bdd5-c374525db946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01bc02ab-001f-4bc1-8b41-595c336da95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulants = [\"Choc\",\"Caff\",\"Amphet\", \"Coke\", \"Crack\", \"Meth\", \"Nicotine\"]\n",
    "depressants = [\"Alcohol\", \"Benzos\", \"Heroin\", \"Legalh\", \"Amyl\", \"VSA\"]\n",
    "hallucinogens = [\"LSD\", \"Mushrooms\", \"Ketamine\", \"Cannabis\", \"Ecstasy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63edcdb1-0bd3-4637-9707-486b46742d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba8df20e-1494-4b35-8020-37be3b64618c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for drug in stimulants:\n",
    "    dff[drug] = dff[drug].apply(lambda x: 0 if x in [\"CL0\", \"CL1\", \"CL2\"] else 1)\n",
    "\n",
    "for drug in depressants:\n",
    "    dff[drug] = dff[drug].apply(lambda x: 0 if x in [\"CL0\", \"CL1\", \"CL2\"] else 1)\n",
    "\n",
    "for drug in hallucinogens:\n",
    "    dff[drug] = dff[drug].apply(lambda x: 0 if x in [\"CL0\", \"CL1\", \"CL2\"] else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b11c4d16-e24d-452f-b0cf-f27e02cd80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Stimulants'] = dff[stimulants].max(axis=1)\n",
    "dff['Depressants'] = dff[depressants].max(axis=1)\n",
    "dff['Hallucinogens'] = dff[hallucinogens].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fab36299-052e-43b9-8f80-fdc254687b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dff.drop(columns=drug_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "601debd0-e21b-45c9-8b14-d9fe6ab1c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_cat = [\"Stimulants\",\"Depressants\",\"Hallucinogens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c8302-857c-400f-a99f-6084d5719b06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9814aa7-3061-4d0a-a1b8-f28c12ae711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHot(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None):\n",
    "        self.columns = columns\n",
    "        self.encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if (self.columns is not None):\n",
    "            self.encoder.fit(X[self.columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if (self.columns is not None):\n",
    "            onehot_encoded = self.encoder.transform(X[self.columns])\n",
    "            feature_names = self.encoder.get_feature_names_out()\n",
    "            result_df = pd.DataFrame(onehot_encoded, columns=feature_names, index=X.index)\n",
    "            return pd.concat([X.drop(columns=self.columns), result_df], axis=1)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f627cbe7-24aa-4316-b723-a7b15b5bee32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ordinal(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns=None, custom_categories=None):\n",
    "        \"\"\"\n",
    "        columns: list of column names to be encoded.\n",
    "        custom_categories: list of lists specifying the order of categories for each column.\n",
    "        \"\"\"\n",
    "        self.columns = columns\n",
    "        self.custom_categories = custom_categories\n",
    "        self.encoder = OrdinalEncoder(categories=custom_categories)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.columns is not None:\n",
    "            self.encoder.fit(X[self.columns])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.columns is not None:\n",
    "            ordinal_encoded = self.encoder.transform(X[self.columns])\n",
    "            result_df = pd.DataFrame(ordinal_encoded, columns=self.columns, index=X.index)\n",
    "            return pd.concat([X.drop(columns=self.columns), result_df], axis=1)\n",
    "        else:\n",
    "            return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b469e28a-0df6-4cfc-a0d1-99433be487f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oneHot = OneHot(demo_cols[demo_cols != \"Education\"])\n",
    "# X = oneHot.fit_transform(pd.concat([df[demo_cols],  df[score_cols]], axis=1))\n",
    "# ordinal = Ordinal([\"Education\"], [education_groups])\n",
    "# X = ordinal.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ac6f2db-ab3e-4e71-97ab-a3a360e9f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dff[drug_cat]\n",
    "# usage_map = dict(zip(np.unique(y), np.array([0, 0, 0, 1, 1, 1, 1])))\n",
    "# y = y.replace(usage_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "656a10f2-e6b5-4540-9ccc-1e15348a4046",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dff[score_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612a006f-6402-4ac7-ae2d-c835a90cf5be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['stimulants'] = df[[\"Choc\", \"Caff\", \"Amphet\", \"Coke\", \"Crack\", \"Meth\", \"Nicotine\"]].any(axis=1).astype(int)\n",
    "# df['depressants'] = df[[\"Alcohol\", \"Benzos\", \"Heroin\", \"Legalh\", \"Amyl\", \"VSA\"]].any(axis=1).astype(int)\n",
    "# df['hallucinogens'] = df[[\"LSD\", \"Mushrooms\", \"Ketamine\", \"Cannabis\", \"Ecstasy\"]].any(axis=1).astype(int)\n",
    "y[[\"Amphet\", \"Coke\", \"Crack\", \"Meth\"]].any(axis=1).astype(int).sum(), \\\n",
    "y[[\"Benzos\", \"Heroin\", \"Legalh\", \"Amyl\", \"VSA\"]].any(axis=1).astype(int).sum(), \\\n",
    "y[[\"LSD\", \"Mushrooms\", \"Ketamine\", \"Ecstasy\"]].any(axis=1).astype(int).sum(), \\\n",
    "y[[\"Cannabis\"]].any(axis=1).astype(int).sum(), \\\n",
    "y[[\"Nicotine\"]].any(axis=1).astype(int).sum(), \\\n",
    "y[[\"Alcohol\"]].any(axis=1).astype(int).sum(), \\\n",
    "y[[\"Caff\"]].any(axis=1).astype(int).sum(), \\\n",
    "y[[\"Choc\"]].any(axis=1).astype(int).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31e3268-3d47-431f-8598-41d5885dc0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96e15e2-ca97-4c5f-8c86-85e787772c28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd9db06-7f78-43f5-b739-67ffd8009ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d4a8c-a6ba-4e4d-bfd8-71afaf769f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b9f21-22e4-4d2b-9201-f24ba096350d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a0f76b1-5fea-4c33-9fd1-501b00eb8d08",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## drug clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6971c91a-01aa-4974-8188-94db888cf292",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[[\"Amphet\", \"Coke\", \"Crack\", \"Meth\",\"Benzos\", \"Heroin\", \"Legalh\", \"Amyl\", \"VSA\", \"LSD\", \"Mushrooms\", \"Ketamine\", \"Ecstasy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8a691-80bf-4234-89a3-0f55b49224aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[y.sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e1f1a-e994-41ff-b58f-12e1bbddcc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb74e02-6767-4104-b7b8-4960e6ba9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_distances = pdist(y, metric='hamming')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b191ff6d-347b-437a-9aa2-077d7da68d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hamming_linkage = linkage(hamming_distances, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa79aa8-228f-4c41-a523-eeda25973ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Hierarchical Clustering Dendrogram (Hamming Distance)\")\n",
    "dendrogram(hamming_linkage, truncate_mode=\"level\", p=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898aadbe-a15a-48c3-a88e-cdd435e63db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = fcluster(hamming_linkage, t=5, criterion='maxclust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535a4ad-026b-4440-aa56-15b8989f5d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[\"cluster\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7a8e8-8382-4aec-b148-03ff6eb21360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Amphet  Coke  Crack  Meth  Benzos  Heroin  Legalh  Amyl  VSA  LSD  \\\n",
      "cluster                                                                      \n",
      "1           110    33      8   113     221      11      78    10   15   15   \n",
      "2            33   130     13     6      41      12      68    24   11    5   \n",
      "3             9     6      4     3       4       3     110    26   14   89   \n",
      "4           155   113      5    54     121       8     188    34   30  187   \n",
      "5           129   135     49   144     148      84     120    39   25   84   \n",
      "\n",
      "         Mushrooms  Ketamine  Ecstasy  \n",
      "cluster                                \n",
      "1               29         2       31  \n",
      "2               28        26       85  \n",
      "3              106        20       88  \n",
      "4              193        84      181  \n",
      "5               78        76      132  \n"
     ]
    }
   ],
   "source": [
    "grouped_drugs = y.groupby('cluster').sum()\n",
    "\n",
    "# Display the drugs captured in each cluster\n",
    "print(grouped_drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6e067-fd8e-4345-b241-bb2a15d7e545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f019b-6b29-48ed-a558-a0112e6f05e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea600d8-1021-445a-b594-5ed3d94e0368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc57b9cf-8b47-4179-91ed-566e69d1ab48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01c6e4db-228d-4230-aacd-eb724cd99ce8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MLSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba45377-11f1-4f18-971d-d5cb60f00baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca07b3-7182-4dd0-8fb3-0e4e624530d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1885, 18)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794b5bd4-6f5b-438e-b459-0add1f62cb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(654, 18)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7705e42-d56b-49a2-8bef-a2d0bb02dff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1885"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y.value_counts()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6ccd6-ca75-4b5e-a7fc-f3961e3ece7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tail_label(df: pd.DataFrame, ql=[0.05, 1.]) -> list:\n",
    "    \"\"\"\n",
    "    Find the underrepresented targets.\n",
    "    Underrepresented targets are those which are observed less than the median occurance.\n",
    "    Targets beyond a quantile limit are filtered.\n",
    "    \"\"\"\n",
    "    irlbl = df.sum(axis=0)\n",
    "    irlbl = irlbl[(irlbl > irlbl.quantile(ql[0])) & ((irlbl < irlbl.quantile(ql[1])))]  # Filtering\n",
    "    irlbl = irlbl.max() / irlbl\n",
    "    threshold_irlbl = irlbl.median()\n",
    "    tail_label = irlbl[irlbl > threshold_irlbl].index.tolist()\n",
    "    return tail_label\n",
    "\n",
    "def get_minority_samples(X: pd.DataFrame, y: pd.DataFrame, ql=[0.05, 1.]):\n",
    "    \"\"\"\n",
    "    return\n",
    "    X_sub: pandas.DataFrame, the feature vector minority dataframe\n",
    "    y_sub: pandas.DataFrame, the target vector minority dataframe\n",
    "    \"\"\"\n",
    "    tail_labels = get_tail_label(y, ql=ql)\n",
    "    index = y[y[tail_labels].apply(lambda x: (x == 1).any(), axis=1)].index.tolist()\n",
    "    \n",
    "    X_sub = X[X.index.isin(index)].reset_index(drop = True)\n",
    "    y_sub = y[y.index.isin(index)].reset_index(drop = True)\n",
    "    return X_sub, y_sub\n",
    "\n",
    "def nearest_neighbour(X: pd.DataFrame, neigh) -> list:\n",
    "    \"\"\"\n",
    "    Give index of 10 nearest neighbor of all the instance\n",
    "    \n",
    "    args\n",
    "    X: np.array, array whose nearest neighbor has to find\n",
    "    \n",
    "    return\n",
    "    indices: list of list, index of 5 NN of each element in X\n",
    "    \"\"\"\n",
    "    nbs = NearestNeighbors(n_neighbors=neigh, metric='euclidean', algorithm='kd_tree').fit(X)\n",
    "    euclidean, indices = nbs.kneighbors(X)\n",
    "    return indices\n",
    "\n",
    "def MLSMOTE(X, y, n_sample, neigh=5):\n",
    "    \"\"\"\n",
    "    Give the augmented data using MLSMOTE algorithm\n",
    "    \n",
    "    args\n",
    "    X: pandas.DataFrame, input vector DataFrame\n",
    "    y: pandas.DataFrame, feature vector dataframe\n",
    "    n_sample: int, number of newly generated sample\n",
    "    \n",
    "    return\n",
    "    new_X: pandas.DataFrame, augmented feature vector data\n",
    "    target: pandas.DataFrame, augmented target vector data\n",
    "    \"\"\"\n",
    "    indices2 = nearest_neighbour(X, neigh=5)\n",
    "    n = len(indices2)\n",
    "    new_X = np.zeros((n_sample, X.shape[1]))\n",
    "    target = np.zeros((n_sample, y.shape[1]))\n",
    "    for i in range(n_sample):\n",
    "        reference = random.randint(0, n-1)\n",
    "        neighbor = random.choice(indices2[reference, 1:])\n",
    "        all_point = indices2[reference]\n",
    "        nn_df = y[y.index.isin(all_point)]\n",
    "        ser = nn_df.sum(axis = 0, skipna = True)\n",
    "        target[i] = np.array([1 if val > 0 else 0 for val in ser])\n",
    "        ratio = random.random()\n",
    "        gap = X.loc[reference,:] - X.loc[neighbor,:]\n",
    "        new_X[i] = np.array(X.loc[reference,:] + ratio * gap)\n",
    "    new_X = pd.DataFrame(new_X, columns=X.columns)\n",
    "    target = pd.DataFrame(target, columns=y.columns)\n",
    "    return new_X, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fbbc76-08c3-45c6-9fe4-66239f2ab514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amyl', 'Coke', 'Heroin', 'Ketamine', 'LSD', 'Meth', 'Mushrooms', 'VSA']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tail_label(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea994e-75de-45cf-b590-5c5402330d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sub, y_sub = get_minority_samples(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344a59d-f2f9-4fb5-bfb3-75a66efb8a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = MLSMOTE(X_sub, y_sub, 500, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44cd733-406c-41f7-b1df-271b90dd2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = pd.concat([X, X_res], axis=0)\n",
    "y_new = pd.concat([y, y_res], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472994c-72c6-490a-bff3-c0f2f9be7615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2385, 16), (2385, 18))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new.shape, y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c24c006-0bfc-4173-94ac-0caff408acf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93152a7b-1c79-485d-96c2-d0713ef4b34d",
   "metadata": {},
   "source": [
    "## trai test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c10c3007-2787-4d93-8856-59c0eb418040",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d781481-f6f4-42c2-b33e-1c273d3c796d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1508, 7), (377, 7))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfced4ba-4b34-44ef-a9a7-da90f28b2a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6642102c-e2b8-4dbe-bff7-b0a08c7fe546",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620c1e2-ef5f-46ea-9425-27d7c7a7d7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f36700c-26fe-4506-8d81-78e6dc310ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic_clf = MultiOutputClassifier(LogisticRegression())\n",
    "logistic_clf = OneVsRestClassifier(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eae922-5396-45a2-8c9c-da529bd0a718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;OneVsRestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.multiclass.OneVsRestClassifier.html\">?<span>Documentation for OneVsRestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>OneVsRestClassifier(estimator=LogisticRegression())</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression())"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335fb77-99b5-4829-b895-1d1feb621c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = logistic_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd826cd0-5d82-40a6-a322-5b19f108bd16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4297082228116711"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70c30a-f4c9-4d37-9129-7e427575bcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(377, 13)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61c14c-4601-4d5c-900e-a57c3cd04ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15649867374005305"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_loss(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda39d2-c7c5-42b0-99e9-1e2d0c3fbae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15649867374005327\n"
     ]
    }
   ],
   "source": [
    "loss = 0\n",
    "for i in range(y_test.shape[0]):\n",
    "    h_loss =hamming_loss(y_test.to_numpy()[i], preds[i])\n",
    "    loss += h_loss\n",
    "print(loss / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409b4d2-c248-4173-aac3-bfce57a9d06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 1 1 1 0 0 1 1 1 1]]\n",
      "[[1 1 0 0 1 0 1 0 0 1 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test.iloc[4:5, :].to_numpy())\n",
    "print(preds[4:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c19d12-567d-4536-93ea-bbd5ae71d12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734a417-f45f-4c55-986d-d419bcdfeb14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cc83cf-b062-469c-81ec-3ab20a3e1b79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f0896-0030-4368-9895-bf6a7f9017cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5025889-3b29-4fc9-b1bb-a94ae2eb2223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5218a560-d275-48d9-8a3e-4ee13c168734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69aa7ca7-d8f6-4051-a7d2-5509c124d755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4403\n",
      "Hamming Loss: 0.1547\n",
      "Accuracy: 0.4635\n",
      "Hamming Loss: 0.1298\n"
     ]
    }
   ],
   "source": [
    "# Initialize the base classifier\n",
    "base_rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
    "\n",
    "# Initialize the MultiOutputClassifier with the base classifier\n",
    "multi_rf = MultiOutputClassifier(base_rf, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "multi_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = multi_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Hamming Loss: {hamming:.4f}')\n",
    "\n",
    "y_pred = multi_rf.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_pred)\n",
    "hamming = hamming_loss(y_train, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Hamming Loss: {hamming:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1a96d-82f7-44f1-8edc-478329661151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04949d13-0f52-4215-9793-9023a29076d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd03da-fd6a-4b26-92a0-eef8a45cf65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f51bdf-315c-49dc-a72e-1b93810609b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a61d9ed5-9804-4f16-9dcc-fcf565b76b16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MLKNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5396269d-a0cc-45d4-bdec-e03fa1a60d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from skmultilearn.adapt import MLkNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f906f-5a8a-4247-ae07-234c164d4ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4164\n",
      "Hamming Loss: 0.1661\n"
     ]
    }
   ],
   "source": [
    "# Initialize KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Wrap KNN with Binary Relevance for multilabel classification\n",
    "#classifier = BinaryRelevance(knn)\n",
    "classifier = knn\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train.to_numpy(), y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test.to_numpy())\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "print(f'Hamming Loss: {hamming:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9c0e3-acf7-44ff-84b2-e39c90159796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming Loss: 0.1655\n",
      "Accuracy: 0.4164\n",
      "Hamming Loss train: 0.1248\n",
      "Accuracy train: 0.4377\n"
     ]
    }
   ],
   "source": [
    "# Initialize MLkNN classifier\n",
    "classifier = MLkNN(k=5)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(np.array(X_train), np.array(y_train))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = classifier.predict(X_test.to_numpy())\n",
    "y_pred_train = classifier.predict(X_train.to_numpy())\n",
    "\n",
    "# Evaluate the model using Hamming loss\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "print(f'Hamming Loss: {hamming:.4f}')\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "hamming = hamming_loss(y_train, y_pred_train)\n",
    "print(f'Hamming Loss train: {hamming:.4f}')\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "print(f'Accuracy train: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f185eaa7-ab1d-4e4e-8d96-971bd22fe86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153558a4-540c-4e7d-9d55-deaab33c1c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2fba59-b506-482d-baa6-3d73dafd108d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57edc18d-426b-4e6f-8878-a0d8bb07f5c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ChianClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1246913-4bc5-4791-9c42-381cc4ea78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import ClassifierChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3193c99b-8f87-4ed7-b4d7-156cd6542fce",
   "metadata": {},
   "source": [
    "## 1. Understanding Label Dependencies:\n",
    "\n",
    "    Substance Use: Drugs like \"Coke\" (Cocaine) and \"Crack\" (Crack Cocaine) might be related.\n",
    "    Party Drugs: \"Ecstasy\", \"LSD\", \"Cannabis\", \"Mushrooms\" might correlate.\n",
    "    Common Use: \"Alcohol\", \"Nicotine\", and \"Caffeine\" are legal and commonly used, possibly indicating less correlation with illegal drugs.\n",
    "    Stimulants: \"Meth\", \"Coke\", \"Amphet\" (Amphetamines) might be grouped.\n",
    "    Psychedelics: \"LSD\", \"Mushrooms\", \"Ketamine\" could be placed near each other.\n",
    "\n",
    "## 2. Proposed Order:\n",
    "\n",
    "> Based on these correlations, a possible order could be:\n",
    "\n",
    "    Caff (Caffeine): Commonly used stimulant, often independent of illicit drug use.\n",
    "    Nicotine: Another common substance, often related to legal use.\n",
    "    Alcohol: Widely used, potentially correlated with social/party drugs.\n",
    "    Cannabis: Often used in combination with both legal substances and party drugs.\n",
    "    Ecstasy: Party drug, possibly correlated with other recreational drugs.\n",
    "    LSD: Psychedelic, often used in similar contexts as Ecstasy.\n",
    "    Mushrooms: Psychedelic, related to LSD.\n",
    "    Ketamine: Used recreationally, might follow other party drugs.\n",
    "    Amphet: Stimulant, related to Meth and other uppers.\n",
    "    Meth: Potent stimulant, likely correlated with other stimulants.\n",
    "    Coke: Another stimulant, similar to Meth and Crack.\n",
    "    Crack: Often related to Coke, might follow it.\n",
    "    Benzos: Depressant, might be used with stimulants or to counteract them.\n",
    "    Heroin: Potent depressant, often correlated with high-risk substance use.\n",
    "    Legalh (Legal Highs): Synthetic drugs, might follow illicit ones.\n",
    "    VSA (Volatile Substance Abuse): Inhalants, possibly correlated with high-risk behaviors.\n",
    "    Choc (Chocolate): Less commonly related to other substances.\n",
    "    Amyl: Nitrites, sometimes used recreationally but less common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25dbf9-1208-4f6e-9d9a-973f1e5134a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4324\n",
      "Hamming Loss: 0.1638\n"
     ]
    }
   ],
   "source": [
    "# Initialize a base classifier\n",
    "#base_classifier = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "base_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "index_list = [4, 16, 0, 5, 9, 13, 15, 11, 1, 14, 7, 8, 3, 10, 12, 17, 6, 2]\n",
    "\n",
    "# Initialize the Classifier Chain\n",
    "chain_classifier = ClassifierChain(base_classifier, order=\"random\", random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "chain_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = chain_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "hamming = hamming_loss(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Hamming Loss: {hamming:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e3b3cc-de2e-4c6e-bb61-d7a509ae114c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5cacb-fabe-4e6b-ac12-ddb39d26b99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c8150-03ec-4950-bea7-1e62ac09f9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f508667d-09e0-4827-8065-a95ff3d403ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "499c06f1-9a09-424b-80d0-65b4aacd5a5b",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d306109-bdd4-4c4b-af27-410579db9005",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_units):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_units)\n",
    "        self.layer2 = nn.Linear(hidden_units, hidden_units)\n",
    "        self.output = nn.Linear(hidden_units, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.output(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccd1322a-da08-4f5b-892e-726e98aa52e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d332bbb6-9978-449e-bbc1-dccba0e41c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.dtype, y_train_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91e0e6d8-b484-4a60-86d3-24a4591aa075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dac4409c-2674-45a7-869b-b30857f511e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "61f2d80a-678e-4c30-9ffe-2ac7f2ad78fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca035152-fdd3-4c71-a6b5-5217eeca7d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, torch.float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].dtype, next(iter(train_dataloader))[1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0463e7ad-7097-4633-a11f-37f0c37189b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "output_shape = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b79f331-b9ba-4b9c-bbcb-c329a8f43221",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP(input_shape, output_shape, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ceef28d7-73d2-4360-864f-926952900667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layer1): Linear(in_features=7, out_features=30, bias=True)\n",
       "  (layer2): Linear(in_features=30, out_features=30, bias=True)\n",
       "  (output): Linear(in_features=30, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e040f06c-2334-4f70-835f-e51e33f0c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3a7ebe8a-deca-40e7-b92f-c9586ce8f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    y_pred = y_pred.round()\n",
    "    correct = (y_pred == y_true).float()  # Get a tensor of 1s and 0s\n",
    "    acc = correct.sum() / correct.numel()  # Mean of correct predictions\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3deb9f30-f8e5-4546-aa4c-d2f188a8f8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \n",
      " ---------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:00<00:08, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.6301888227462769 | train acc: 0.7343750596046448 | val loss: 0.5353474617004395 | val acc: 0.8455209136009216\n",
      "\n",
      "Epoch: 1 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.4163576364517212 | train acc: 0.8524305820465088 | val loss: 0.31852373480796814 | val acc: 0.894618034362793\n",
      "\n",
      "Epoch: 2 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2822273075580597 | train acc: 0.8949651718139648 | val loss: 0.26868078112602234 | val acc: 0.8961110711097717\n",
      "\n",
      "Epoch: 3 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.25164297223091125 | train acc: 0.9021267294883728 | val loss: 0.2594124674797058 | val acc: 0.8952431082725525\n",
      "\n",
      "Epoch: 4 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:00<00:06, 14.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.24216322600841522 | train acc: 0.9042968153953552 | val loss: 0.25698092579841614 | val acc: 0.8949999809265137\n",
      "\n",
      "Epoch: 5 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.23729568719863892 | train acc: 0.9051650166511536 | val loss: 0.25346559286117554 | val acc: 0.8978472352027893\n",
      "\n",
      "Epoch: 6 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.23570650815963745 | train acc: 0.9045140743255615 | val loss: 0.25226473808288574 | val acc: 0.901562511920929\n",
      "\n",
      "Epoch: 7 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2312362790107727 | train acc: 0.907118022441864 | val loss: 0.24932505190372467 | val acc: 0.8994444012641907\n",
      "\n",
      "Epoch: 8 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:00<00:05, 17.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.23309604823589325 | train acc: 0.905164897441864 | val loss: 0.24949796497821808 | val acc: 0.9000694751739502\n",
      "\n",
      "Epoch: 9 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.23162150382995605 | train acc: 0.9040799140930176 | val loss: 0.24929994344711304 | val acc: 0.9000694751739502\n",
      "\n",
      "Epoch: 10 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22987760603427887 | train acc: 0.9055989384651184 | val loss: 0.24929702281951904 | val acc: 0.8977083563804626\n",
      "\n",
      "Epoch: 11 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.23328624665737152 | train acc: 0.903428852558136 | val loss: 0.24829530715942383 | val acc: 0.8994445204734802\n",
      "\n",
      "Epoch: 12 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:00<00:04, 18.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.23191790282726288 | train acc: 0.9060329794883728 | val loss: 0.24860693514347076 | val acc: 0.8994445204734802\n",
      "\n",
      "Epoch: 13 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22739601135253906 | train acc: 0.9062498211860657 | val loss: 0.2524358928203583 | val acc: 0.8993403315544128\n",
      "\n",
      "Epoch: 14 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22633536159992218 | train acc: 0.9069010615348816 | val loss: 0.24796682596206665 | val acc: 0.9005556106567383\n",
      "\n",
      "Epoch: 15 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22685475647449493 | train acc: 0.9082031846046448 | val loss: 0.24806971848011017 | val acc: 0.9031597971916199\n",
      "\n",
      "Epoch: 16 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:01<00:04, 19.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22638142108917236 | train acc: 0.905599057674408 | val loss: 0.24838566780090332 | val acc: 0.8985764980316162\n",
      "\n",
      "Epoch: 17 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22524482011795044 | train acc: 0.9069010615348816 | val loss: 0.24750261008739471 | val acc: 0.8979514241218567\n",
      "\n",
      "Epoch: 18 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22486889362335205 | train acc: 0.909071147441864 | val loss: 0.2478078454732895 | val acc: 0.8996875882148743\n",
      "\n",
      "Epoch: 19 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22826410830020905 | train acc: 0.904296875 | val loss: 0.24859845638275146 | val acc: 0.8974652886390686\n",
      "\n",
      "Epoch: 20 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:01<00:03, 19.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.23006512224674225 | train acc: 0.90625 | val loss: 0.2470775693655014 | val acc: 0.8985764384269714\n",
      "\n",
      "Epoch: 21 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22617805004119873 | train acc: 0.9086371064186096 | val loss: 0.24943490326404572 | val acc: 0.900069534778595\n",
      "\n",
      "Epoch: 22 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22784924507141113 | train acc: 0.9038627743721008 | val loss: 0.24827761948108673 | val acc: 0.9011805653572083\n",
      "\n",
      "Epoch: 23 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22431844472885132 | train acc: 0.9086372256278992 | val loss: 0.24666564166545868 | val acc: 0.8996875286102295\n",
      "\n",
      "Epoch: 24 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22173261642456055 | train acc: 0.9105903506278992 | val loss: 0.24849854409694672 | val acc: 0.8983333706855774\n",
      "\n",
      "Epoch: 25 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:01<00:03, 20.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22295336425304413 | train acc: 0.9090710282325745 | val loss: 0.24824361503124237 | val acc: 0.8977084159851074\n",
      "\n",
      "Epoch: 26 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22414632141590118 | train acc: 0.908203125 | val loss: 0.24788536131381989 | val acc: 0.9005555510520935\n",
      "\n",
      "Epoch: 27 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22566747665405273 | train acc: 0.9038628935813904 | val loss: 0.2496020644903183 | val acc: 0.8983333110809326\n",
      "\n",
      "Epoch: 28 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22293907403945923 | train acc: 0.9084203243255615 | val loss: 0.2495066076517105 | val acc: 0.9003124833106995\n",
      "\n",
      "Epoch: 29 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:01<00:03, 19.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22105096280574799 | train acc: 0.909071147441864 | val loss: 0.25272271037101746 | val acc: 0.8989583849906921\n",
      "\n",
      "Epoch: 30 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22188395261764526 | train acc: 0.905381977558136 | val loss: 0.24981309473514557 | val acc: 0.8994445204734802\n",
      "\n",
      "Epoch: 31 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22078441083431244 | train acc: 0.9088541865348816 | val loss: 0.2507660388946533 | val acc: 0.9000694751739502\n",
      "\n",
      "Epoch: 32 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22050388157367706 | train acc: 0.9073352217674255 | val loss: 0.24850992858409882 | val acc: 0.8996875286102295\n",
      "\n",
      "Epoch: 33 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:01<00:03, 19.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21873287856578827 | train acc: 0.9099392294883728 | val loss: 0.25032684206962585 | val acc: 0.8992013931274414\n",
      "\n",
      "Epoch: 34 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22474347054958344 | train acc: 0.9086372256278992 | val loss: 0.25020280480384827 | val acc: 0.8992014527320862\n",
      "\n",
      "Epoch: 35 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21717287600040436 | train acc: 0.9121094346046448 | val loss: 0.24826572835445404 | val acc: 0.8985764384269714\n",
      "\n",
      "Epoch: 36 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:02<00:03, 18.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22204844653606415 | train acc: 0.9071180820465088 | val loss: 0.24830001592636108 | val acc: 0.8988194465637207\n",
      "\n",
      "Epoch: 37 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22784675657749176 | train acc: 0.907118022441864 | val loss: 0.24930526316165924 | val acc: 0.8988195061683655\n",
      "\n",
      "Epoch: 38 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21874932944774628 | train acc: 0.9084201455116272 | val loss: 0.2490883320569992 | val acc: 0.8994444012641907\n",
      "\n",
      "Epoch: 39 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21783997118473053 | train acc: 0.9116753935813904 | val loss: 0.2500963509082794 | val acc: 0.8994444012641907\n",
      "\n",
      "Epoch: 40 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:02<00:02, 19.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.2167133092880249 | train acc: 0.9097222685813904 | val loss: 0.24815259873867035 | val acc: 0.8988194465637207\n",
      "\n",
      "Epoch: 41 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21860520541667938 | train acc: 0.9097223281860352 | val loss: 0.2513388693332672 | val acc: 0.8994445204734802\n",
      "\n",
      "Epoch: 42 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21726615726947784 | train acc: 0.9095051884651184 | val loss: 0.24957771599292755 | val acc: 0.8985764384269714\n",
      "\n",
      "Epoch: 43 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22208277881145477 | train acc: 0.9077691435813904 | val loss: 0.2498232126235962 | val acc: 0.9003124833106995\n",
      "\n",
      "Epoch: 44 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21607153117656708 | train acc: 0.912109375 | val loss: 0.24998122453689575 | val acc: 0.9003124833106995\n",
      "\n",
      "Epoch: 45 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [00:02<00:02, 19.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22011001408100128 | train acc: 0.9095051884651184 | val loss: 0.2513626515865326 | val acc: 0.9011805653572083\n",
      "\n",
      "Epoch: 46 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2144826203584671 | train acc: 0.9134113192558289 | val loss: 0.2504197955131531 | val acc: 0.9011805653572083\n",
      "\n",
      "Epoch: 47 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2162960171699524 | train acc: 0.9095051884651184 | val loss: 0.25188741087913513 | val acc: 0.9003124833106995\n",
      "\n",
      "Epoch: 48 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2143210768699646 | train acc: 0.9099392294883728 | val loss: 0.2515893280506134 | val acc: 0.8983333706855774\n",
      "\n",
      "Epoch: 49 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [00:02<00:02, 19.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.22331680357456207 | train acc: 0.908854067325592 | val loss: 0.25098031759262085 | val acc: 0.9003124833106995\n",
      "\n",
      "Epoch: 50 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2145870476961136 | train acc: 0.9101561903953552 | val loss: 0.2520003914833069 | val acc: 0.8992014527320862\n",
      "\n",
      "Epoch: 51 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21713852882385254 | train acc: 0.9097221493721008 | val loss: 0.25224336981773376 | val acc: 0.8983333706855774\n",
      "\n",
      "Epoch: 52 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2120819240808487 | train acc: 0.9131943583488464 | val loss: 0.2523268163204193 | val acc: 0.8974652886390686\n",
      "\n",
      "Epoch: 53 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [00:03<00:02, 19.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21253333985805511 | train acc: 0.9112412333488464 | val loss: 0.25287362933158875 | val acc: 0.8965972065925598\n",
      "\n",
      "Epoch: 54 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2134322077035904 | train acc: 0.913411557674408 | val loss: 0.2513786554336548 | val acc: 0.8974652886390686\n",
      "\n",
      "Epoch: 55 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21316157281398773 | train acc: 0.9097222685813904 | val loss: 0.2513190805912018 | val acc: 0.8953471779823303\n",
      "\n",
      "Epoch: 56 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21331824362277985 | train acc: 0.9129775166511536 | val loss: 0.2535392940044403 | val acc: 0.8965973258018494\n",
      "\n",
      "Epoch: 57 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:03<00:02, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21285732090473175 | train acc: 0.9125434756278992 | val loss: 0.251829594373703 | val acc: 0.8931249976158142\n",
      "\n",
      "Epoch: 58 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21228672564029694 | train acc: 0.9134113788604736 | val loss: 0.25231608748435974 | val acc: 0.8922569751739502\n",
      "\n",
      "Epoch: 59 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20947426557540894 | train acc: 0.9134114384651184 | val loss: 0.25380387902259827 | val acc: 0.8922569751739502\n",
      "\n",
      "Epoch: 60 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20771092176437378 | train acc: 0.912977397441864 | val loss: 0.25229454040527344 | val acc: 0.8942360877990723\n",
      "\n",
      "Epoch: 61 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [00:03<00:01, 20.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2089930921792984 | train acc: 0.9147136211395264 | val loss: 0.25511133670806885 | val acc: 0.893125057220459\n",
      "\n",
      "Epoch: 62 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2154027670621872 | train acc: 0.912543535232544 | val loss: 0.25442999601364136 | val acc: 0.8974652886390686\n",
      "\n",
      "Epoch: 63 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2096877098083496 | train acc: 0.9138455390930176 | val loss: 0.2522173225879669 | val acc: 0.8922569751739502\n",
      "\n",
      "Epoch: 64 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2099006325006485 | train acc: 0.9116753935813904 | val loss: 0.25298288464546204 | val acc: 0.8965973258018494\n",
      "\n",
      "Epoch: 65 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [00:03<00:01, 20.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2070450633764267 | train acc: 0.9162325859069824 | val loss: 0.2552933990955353 | val acc: 0.8948611617088318\n",
      "\n",
      "Epoch: 66 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2096455693244934 | train acc: 0.9116752743721008 | val loss: 0.254997581243515 | val acc: 0.893125057220459\n",
      "\n",
      "Epoch: 67 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21050117909908295 | train acc: 0.9147135615348816 | val loss: 0.2544387876987457 | val acc: 0.8968402743339539\n",
      "\n",
      "Epoch: 68 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.21057479083538055 | train acc: 0.9144964218139648 | val loss: 0.2533847391605377 | val acc: 0.8957292437553406\n",
      "\n",
      "Epoch: 69 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [00:03<00:01, 20.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.2060333490371704 | train acc: 0.9142796397209167 | val loss: 0.25486546754837036 | val acc: 0.893125057220459\n",
      "\n",
      "Epoch: 70 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20781487226486206 | train acc: 0.9121094346046448 | val loss: 0.256174772977829 | val acc: 0.8948611617088318\n",
      "\n",
      "Epoch: 71 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2134801596403122 | train acc: 0.9101564288139343 | val loss: 0.25490841269493103 | val acc: 0.8922569751739502\n",
      "\n",
      "Epoch: 72 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20716412365436554 | train acc: 0.9149306416511536 | val loss: 0.25689640641212463 | val acc: 0.8917708396911621\n",
      "\n",
      "Epoch: 73 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20482327044010162 | train acc: 0.915147602558136 | val loss: 0.2566646635532379 | val acc: 0.893125057220459\n",
      "\n",
      "Epoch: 74 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20506338775157928 | train acc: 0.9134116768836975 | val loss: 0.2545267641544342 | val acc: 0.8957292437553406\n",
      "\n",
      "Epoch: 75 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2046108841896057 | train acc: 0.9157984256744385 | val loss: 0.25527673959732056 | val acc: 0.893993079662323\n",
      "\n",
      "Epoch: 76 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [00:04<00:01, 18.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2057093232870102 | train acc: 0.9157984852790833 | val loss: 0.25767281651496887 | val acc: 0.8939931392669678\n",
      "\n",
      "Epoch: 77 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20481859147548676 | train acc: 0.9164496064186096 | val loss: 0.2565372884273529 | val acc: 0.8968402743339539\n",
      "\n",
      "Epoch: 78 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20291592180728912 | train acc: 0.9162325859069824 | val loss: 0.25597214698791504 | val acc: 0.893993079662323\n",
      "\n",
      "Epoch: 79 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20674113929271698 | train acc: 0.9151475429534912 | val loss: 0.2573094069957733 | val acc: 0.893750011920929\n",
      "\n",
      "Epoch: 80 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [00:04<00:00, 19.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train loss: 0.20530706644058228 | train acc: 0.9123263359069824 | val loss: 0.2586398720741272 | val acc: 0.8920139670372009\n",
      "\n",
      "Epoch: 81 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20330990850925446 | train acc: 0.9155815243721008 | val loss: 0.25906652212142944 | val acc: 0.8920139670372009\n",
      "\n",
      "Epoch: 82 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2062687873840332 | train acc: 0.9123263359069824 | val loss: 0.25810685753822327 | val acc: 0.8939931392669678\n",
      "\n",
      "Epoch: 83 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2030431181192398 | train acc: 0.9164497256278992 | val loss: 0.25710779428482056 | val acc: 0.8957292437553406\n",
      "\n",
      "Epoch: 84 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20670665800571442 | train acc: 0.9116751551628113 | val loss: 0.25741612911224365 | val acc: 0.8913888931274414\n",
      "\n",
      "Epoch: 85 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [00:04<00:00, 19.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20226578414440155 | train acc: 0.9147135615348816 | val loss: 0.2581195831298828 | val acc: 0.8920139670372009\n",
      "\n",
      "Epoch: 86 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20427997410297394 | train acc: 0.9140625596046448 | val loss: 0.25760170817375183 | val acc: 0.8957292437553406\n",
      "\n",
      "Epoch: 87 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20206189155578613 | train acc: 0.916666567325592 | val loss: 0.2582460939884186 | val acc: 0.8959722518920898\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [00:04<00:00, 17.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2018072009086609 | train acc: 0.9157986640930176 | val loss: 0.2566763162612915 | val acc: 0.8942360877990723\n",
      "\n",
      "Epoch: 89 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20561401546001434 | train acc: 0.9129772186279297 | val loss: 0.25851181149482727 | val acc: 0.8965972065925598\n",
      "\n",
      "Epoch: 90 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20857290923595428 | train acc: 0.9112412929534912 | val loss: 0.2588072121143341 | val acc: 0.8965972065925598\n",
      "\n",
      "Epoch: 91 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [00:05<00:00, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20060913264751434 | train acc: 0.9171008467674255 | val loss: 0.25944212079048157 | val acc: 0.8974652290344238\n",
      "\n",
      "Epoch: 92 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20352090895175934 | train acc: 0.912109375 | val loss: 0.26205238699913025 | val acc: 0.8917708396911621\n",
      "\n",
      "Epoch: 93 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.2012830376625061 | train acc: 0.914713442325592 | val loss: 0.2591265141963959 | val acc: 0.8957292437553406\n",
      "\n",
      "Epoch: 94 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20123399794101715 | train acc: 0.9147136211395264 | val loss: 0.2590590715408325 | val acc: 0.893750011920929\n",
      "\n",
      "Epoch: 95 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [00:05<00:00, 17.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.19952203333377838 | train acc: 0.9142794609069824 | val loss: 0.2595749795436859 | val acc: 0.8948611617088318\n",
      "\n",
      "Epoch: 96 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.20269525051116943 | train acc: 0.9138455390930176 | val loss: 0.2610706090927124 | val acc: 0.893993079662323\n",
      "\n",
      "Epoch: 97 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.1996910721063614 | train acc: 0.9157986044883728 | val loss: 0.2649052143096924 | val acc: 0.8926389217376709\n",
      "\n",
      "Epoch: 98 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.1988070011138916 | train acc: 0.9155816435813904 | val loss: 0.2611263692378998 | val acc: 0.8965972065925598\n",
      "\n",
      "Epoch: 99 \n",
      " ---------\n",
      "looked at 0 / 1508 samples\n",
      "looked at 320 / 1508 samples\n",
      "looked at 640 / 1508 samples\n",
      "looked at 960 / 1508 samples\n",
      "looked at 1280 / 1508 samples\n",
      "\n",
      "train loss: 0.19994103908538818 | train acc: 0.915147602558136 | val loss: 0.26077935099601746 | val acc: 0.8948610424995422\n",
      "\n",
      "\n",
      "train time: 5.464459810999983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "start = timer()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch} \\n ---------\")\n",
    "\n",
    "    train_loss, train_acc = 0, 0\n",
    "\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        y_pred = model(X)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        train_acc += accuracy(y, y_pred)\n",
    "\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print(f\"looked at {batch * len(X)} / {len(train_dataloader.dataset)} samples\")\n",
    "\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "\n",
    "    test_loss, test_acc = 0, 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y, in test_dataloader:\n",
    "\n",
    "            test_pred = model(X)\n",
    "\n",
    "            test_acc += accuracy(y, test_pred)\n",
    "            test_loss += loss_fn(test_pred, y)\n",
    "\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    print(f\"\\ntrain loss: {train_loss} | train acc: {train_acc} | val loss: {test_loss} | val acc: {test_acc}\\n\")\n",
    "\n",
    "            \n",
    "end = timer()\n",
    "print_train_time(start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c8ef281e-6042-48c0-9564-f12ab8d460ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10513888888888889\n",
      "tensor(0.8949)\n",
      "0.08311631944444446\n",
      "tensor(0.9169)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "\n",
    "    total_h_loss = 0\n",
    "    total_acc = 0\n",
    "    for X, y in test_dataloader:\n",
    "        y_pred = model(X)\n",
    "        acc = accuracy(y, y_pred)\n",
    "        h_loss = hamming_loss(y, y_pred.round())\n",
    "        total_h_loss += h_loss\n",
    "        total_acc += acc\n",
    "    print(total_h_loss/ len(test_dataloader))\n",
    "    print(total_acc / len(test_dataloader))\n",
    "\n",
    "    total_h_loss = 0\n",
    "    total_acc = 0\n",
    "    for X, y in train_dataloader:\n",
    "        y_pred = model(X)\n",
    "        acc = accuracy(y, y_pred)\n",
    "        h_loss = hamming_loss(y, y_pred.round())\n",
    "        total_h_loss += h_loss\n",
    "        total_acc += acc\n",
    "    print(total_h_loss/ len(train_dataloader))\n",
    "    print(total_acc / len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f2a9038-090f-4146-bd42-4e2f85092a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "scripted_model = torch.jit.script(model)  # Or torch.jit.trace(model, example_input)\n",
    "scripted_model.save(\"mlp_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f642c93f-fb12-4be7-80e1-5be00f59757b",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {\"A\": 1.27, \"B\": -0.45, \"C\": 0.85, \"D\": -1.75, \"E\": 0.65, \"F\": -0.35, \"G\": 1.20}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e480b2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.9900, 0.8514]])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    tmp = torch.tensor(np.array(list(zip(temp.values()))), dtype=torch.float32)\n",
    "    tmp = tmp.transpose(0, 1)\n",
    "    pred = model(tmp)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0fb2754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 7])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a9f7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
